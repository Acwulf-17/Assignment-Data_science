{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7000c194-ca17-4216-bf08-0f0eafc5297e",
   "metadata": {},
   "source": [
    "Q.1.Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd4a5e-0569-4ded-b050-7beb98c44e14",
   "metadata": {},
   "source": [
    "Min-Max scaling is a data preprocessing technique used to rescale numerical features within a specific range, typically between 0 and 1. It transforms the data in such a way that the minimum value becomes 0, the maximum value becomes 1, and all other values are linearly scaled in between.\n",
    "\n",
    "The formula for Min-Max scaling for a single data point x is:\n",
    "\n",
    "x(new)= [x-min(X)]/[max(X)- min(X)]\n",
    "\n",
    "\n",
    "Suppose you have a dataset of house prices with a range of values between $50,000 and $1,000,000. To perform Min-Max scaling on a house price of $75,000, you would apply the formula as follows:\n",
    "\n",
    "x(new) = (75000-50000)/(1000000-50000) = 25000/95000 = 0.0263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb75136-39b5-4a27-b92d-27d82f85ec3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b704a97-e485-41e0-925b-d340b17f14ff",
   "metadata": {},
   "source": [
    "Q.2.Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f1aba-f7ce-4047-9fae-0bb4e233046b",
   "metadata": {},
   "source": [
    "The unit vector technique, also known as unit vector normalization or \"unit length scaling,\" is a feature scaling method that transforms data in a way that each data point lies on the surface of a unit hypersphere. This technique ensures that all feature vectors have a magnitude or length of 1.\n",
    "\n",
    "Difference from Min-Max Scaling:\n",
    "\n",
    "Min-Max scaling scales the data to a specific range (e.g., 0 to 1), while the unit vector technique scales the data to have a magnitude of 1. As a result, the unit vector technique maintains the direction of the data points, which can be useful in certain algorithms like cosine similarity calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128b0aa-7f3c-494e-ac64-0607b04798ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8767e45e-864f-4a97-a65d-5fd68382a9d6",
   "metadata": {},
   "source": [
    "Q.3.Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31526eac-ba34-4f7f-a7b6-e5620d12c8ca",
   "metadata": {},
   "source": [
    "PCA, or Principal Component Analysis, is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional representation while preserving the most important information and reducing redundancy. It does this by identifying linear combinations of the original features called \"principal components\" that capture the maximum variance in the data.\n",
    "\n",
    "The steps for PCA are as follows:\n",
    "\n",
    "Standardize the data (subtract the mean and divide by the standard deviation for each feature).\n",
    "\n",
    "Compute the covariance matrix of the standardized data.\n",
    "\n",
    "Compute the eigenvalues and eigenvectors of the covariance matrix.\n",
    "\n",
    "Sort the eigenvalues in descending order and select the top kk eigenvectors to form the principal components.\n",
    "\n",
    "Project the data onto the selected principal components to obtain the reduced-dimensional representation.\n",
    "\n",
    "Example:\n",
    "\n",
    "Suppose you have a dataset with various features related to customer behavior, such as purchase history, website activity, and demographics, resulting in a high-dimensional dataset. By applying PCA, you can reduce these features to a smaller set of principal components that capture the most significant variation in the data. For example, if you retain the top 3 principal components, you may find that these components explain 90% of the total variance in the original data, effectively reducing the dimensionality of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac2b23-57c0-4a63-b4ef-d4cdba294d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f212865c-1e33-4a40-b630-7da5db2ad2c6",
   "metadata": {},
   "source": [
    "Q,4,Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36354ac-a205-4c54-b8e4-106a69d2d468",
   "metadata": {},
   "source": [
    "PCA can be used for feature extraction, especially when you want to reduce the dimensionality of your data while preserving as much information as possible. In PCA, the principal components are linear combinations of the original features, and they represent the most informative directions in the data space. These principal components can be considered as \"new\" features extracted from the original ones.\n",
    "\n",
    "Example:\n",
    "\n",
    "Suppose you have a dataset with 100 features that describe a patient's medical history. By applying PCA, you can reduce the dimensionality of the data to, let's say, 10 principal components. These 10 principal components are the result of combining information from the original 100 features. You can then use these 10 principal components as a reduced set of features in your predictive model for a health-related task, like disease prediction. This not only simplifies the model but also mitigates the risk of overfitting and can improve interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca310a-7e45-4fbd-a22e-391574d29e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07ea450d-6999-4ff9-a4a9-09a9be4f9585",
   "metadata": {},
   "source": [
    "Q.5.Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037184d-edd6-4b7f-83a8-de729e43db7f",
   "metadata": {},
   "source": [
    "In a food delivery recommendation system, you have features such as price, rating, and delivery time. Min-Max scaling can be used to preprocess these features to ensure they are within a common range (e.g., 0 to 1) so that they don't disproportionately influence the recommendation process.\n",
    "\n",
    "Here's how you would use Min-Max scaling:\n",
    "\n",
    "Identify the features you want to scale, such as price, rating, and delivery time.\n",
    "\n",
    "Determine the minimum and maximum values for each feature in your dataset.\n",
    "\n",
    "Apply the Min-Max scaling formula to each data point for each feature, ensuring that each feature is rescaled to the range of 0 to 1.\n",
    "\n",
    "For example, if the price of a menu item ranges from $5 to $25, you can use Min-Max scaling to transform these values to a range between 0 and 1. This ensures that the price feature is on a similar scale as other features like rating and delivery time, making it easier for your recommendation system to consider each feature's contribution equally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0f7c2-edf1-4ccb-81dc-4af54922692b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "949727d2-614c-4e79-97e5-5f3b024c3245",
   "metadata": {},
   "source": [
    "Q.6.Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffef85-3bac-4c4f-8d11-67a364284d1b",
   "metadata": {},
   "source": [
    "For a project to predict stock prices using a dataset with numerous features, PCA can be employed to reduce the dimensionality of the dataset. This is beneficial for simplifying the modeling process and improving model generalization.\n",
    "\n",
    "Here's how you would use PCA for this purpose:\n",
    "\n",
    "Standardize the dataset by subtracting the mean and dividing by the standard deviation for each feature. This is essential as PCA is sensitive to the scale of the data.\n",
    "\n",
    "Apply PCA to the standardized data to extract the principal components. You can decide how many principal components to retain based on the desired level of dimensionality reduction and the explained variance.\n",
    "\n",
    "Train your stock price prediction model using the reduced-dimensional dataset containing the selected principal components.\n",
    "\n",
    "By using PCA, you can reduce the number of features from the original dataset while retaining the most significant variance in the data, potentially improving the model's performance and reducing the risk of overfitting.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
